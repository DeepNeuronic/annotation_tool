{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 1:** Import the necessary **modules**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "\n",
        "# prevent the creation of \"__pycache__\"\n",
        "sys.dont_write_bytecode = True\n",
        "\n",
        "from resources.utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 2:** Set the **target video** and set up the annotation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "VIDEO_PATH = \"../my_videos/new_videos/joao_brito_102_0.mp4\"\n",
        "CFG_FILE_PATH = \"resources/ByteTrack/exps/example/mot/yolox_x_mix_det.py\"\n",
        "TRAINED_MODEL_PATH = \"resources/ByteTrack/pretrained/bytetrack_x_mot20.tar\"\n",
        "\n",
        "initial_setup()\n",
        "extract_frames(video_path = VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 3:** Call **the tracking algorithm** and get **tracked bounding boxes** for the target video (as well as, some **debugging resources** - e.g., CVAT task, ID visualization, and more)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_tracked_bounding_boxes(video_path = VIDEO_PATH, cfg_file_path = CFG_FILE_PATH, trained_model_path = TRAINED_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**(OPTIONAL) STEP 4.1:** Review the **tracking** (i.e., non-existent IDs, poorly attributed IDs, bounding boxes that shouldn't have been placed, etc...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "REMOVE_LIST = [\n",
        "    #[\"\", 1, -1],\n",
        "]\n",
        "\n",
        "REMAP_LIST = [\n",
        "    #[\"\", 1, -1, \"\"],\n",
        "]\n",
        "\n",
        "fix_tracking(remove_list = REMOVE_LIST, remap_list = REMAP_LIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**(OPTIONAL) STEP 4.2:** Review the **actual bounding boxes** (i.e., poorly placed or entirely non-existent bounding boxes) <ins>**OR**</ins> add bounding boxes for inanimate objects (i.e., cars, fires / explosions, etc...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Go to **CVAT** (**has to be through <ins>https://cvat.org</ins> on a supported browser** - Firefox or Chrome)\n",
        "2. Click on \"**Create from backup**\" to upload the .zip file from the previous step (i.e., a CVAT task **pre-loaded with the automatic annotations**)\n",
        "3. **Fix or add** any bounding boxes (**make sure the IDs are properly set**)\n",
        "4. Once finished, **download the annotations in the COCO format** and place them in the ***/output*** folder with the name \"**coco.zip**\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 5:** Annotate the **actions** being performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ACTIONS_LIST = [\n",
        "    [\"1\", 1, 53, \"shooting\"],\n",
        "    [\"1\", 54, -1, \"carrying_weapon\"],\n",
        "    [\"2\", 1, -1, \"carrying_weapon\"],\n",
        "]\n",
        "\n",
        "annotate_actions(video_path = VIDEO_PATH, actions_list = ACTIONS_LIST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**(OPTIONAL) STEP 6:** Visualize the final annotations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_annotations(video_path = VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**STEP 7:** Finalize everything. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "finalize(video_path = VIDEO_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[DeepNeuronic] Semi-Automatic Annotations.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
